{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create specimen instances \n",
    "\n",
    "Demonstration script for generating instances from metadata that is provided \n",
    "in the specimen_template.xlsx file without requiring prior python experience. \n",
    "\n",
    "With this notebook you can do the following:\n",
    "1. Import user-defined specimen metadata\n",
    "2. Convert metadata into openMINDS instances\n",
    "3. Upload newly created instances to the KGE\n",
    "4. Add newly created instances to a dataset version under \"studiedSpecimen\"\n",
    "\n",
    "To be able to run the script, you need to the following requirements:\n",
    "- Python version >= 3.6\n",
    "- openMINDS package (can be downloaded from https://pypi.org/project/openMINDS/)\n",
    "- read and write permission to the KG via the API\n",
    "\n",
    "Run the script and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "\n",
    "from metabot import openMINDS_wrapper\n",
    "w = openMINDS_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the location of your template file\n",
    "\n",
    "We first need to define the location of your template file. This notebook asks you whether the template file is stored in the same location as the script. Press \"y\" if this is the case. If it is stored elsewhere, you press \"n\" and define the path to your file.\n",
    "\n",
    "An output folder is automatically created in which the instances will be stored. The output folder is put in the same location as the template file and the name of the folder is \"createdInstances_[date]_[time]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Location of the files\n",
    "cwd = os.getcwd()\n",
    "answer = input(\"Is this where your files are stored: \" + cwd + \"? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    fpath = cwd\n",
    "elif answer == \"n\":\n",
    "    fpath = input(\"Please define you path: \")\n",
    "     \n",
    "fpath = fpath + \"\\\\\" \n",
    "os.chdir(fpath)\n",
    "\n",
    "# Make output folder is it does not exist yet\n",
    "now = datetime.now()\n",
    "output_path = \"createdInstances\" + \"_\" + now.strftime(\"%d%m%Y_%H%M\") + \"\\\\\"\n",
    "if os.path.isdir(output_path):\n",
    "    print(\"Output folder already exists\")\n",
    "else:\n",
    "    print(\"Output folder does not exist, making folder\")        \n",
    "    os.mkdir(output_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import metadata and create instances\n",
    "\n",
    "We then define the name of the template file (without the \".xlsx\" extension) and import the metadata. Everything that is defined in the template file will be converted into an instance. \n",
    "\n",
    "Remember to use 1 row per specimen. If you would like to create 2 or more states (time points) per specimen with specific metadata (e.g. age, weight, attribute), use 1 row per specimen state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file with the specimen metadata\n",
    "metadata_file = input(\"What is the name of your specimen file (e.g. specimen_template.xlsx)? \")\n",
    "fileLocation = fpath + metadata_file + \".xlsx\"\n",
    "\n",
    "specimenInfo = pd.read_excel(fileLocation)\n",
    "\n",
    "specimenType = specimenInfo.specimenType.to_list()\n",
    "\n",
    "if \"subjectGroup\" in specimenType:\n",
    "    SG_info = specimenInfo[specimenInfo.specimenType == \"subjectGroup\"].reset_index(drop=True) \n",
    "    SG_data = w.makeSubjectCollections(SG_info, output_path)\n",
    "\n",
    "if \"subject\" in specimenType:\n",
    "    subject_info = specimenInfo[specimenInfo.specimenType == \"subject\"].reset_index(drop=True) \n",
    "    if 'SG_data' in locals():\n",
    "        subject_info = w.findGroup(subject_info, SG_data)\n",
    "    subject_data = w.makeSubjectCollections(subject_info, output_path)\n",
    "\n",
    "if \"tsc\" in specimenType:\n",
    "    tsc_info = specimenInfo[specimenInfo.specimenType == \"tsc\"].reset_index(drop=True) \n",
    "    if 'subject_data' in locals():\n",
    "        tsc_info = w.findGroup(tsc_info, subject_data)\n",
    "    tsc_data = w.makeSampleCollections(tsc_info, output_path)\n",
    "\n",
    "if \"ts\" in specimenType:\n",
    "    ts_info = specimenInfo[specimenInfo.specimenType == \"ts\"].reset_index(drop=True)\n",
    "    if 'tsc_data' in locals():\n",
    "        ts_info = w.findGroup(ts_info, tsc_data) \n",
    "    ts_data = w.makeSampleCollections(ts_info, output_path)\n",
    "\n",
    "# Saving an overview file in the output folder for future reference\n",
    "print(\"\\nOverview file is saved in the output folder \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the instances to the KGE\n",
    "\n",
    "Once we have created the instances, we can immediately upload them to the KGE. For this you will need to authorise yourself with an authentication token. You can find that token in the KGE editor.\n",
    "\n",
    "If you are not ready to upload the instances, press \"n\". You can always add them later using the ex3.py script.\n",
    "\n",
    "If you uploaded them, but you made a mistake and would like to remove all the instances? Use the ex4.py script to delete the instance from the KGE.\n",
    "\n",
    "### Add specimen to a dataset version\n",
    "\n",
    "If you have chosen to upload the instances to the KGE immediately, you get the opportunity to add the specimen you created to a dataset version. For this, you need to give the uuid of the dataset version and all the instances will be added. \n",
    "\n",
    "If you decide against adding the instances, then you will have to add the instances to the dataset version manually (under \"studiedSpecimen\") or you can run script ex5.py later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload instances to the KGE\n",
    "answer = input(\"Would you like to upload the instances you created to the KGE? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    token = getpass(prompt=\"Please enter your KG token (or Enter to skip uploading to the KG): \")\n",
    "    instances_fnames = glob.glob(output_path + \"*\\\\*\", recursive = True)\n",
    "\n",
    "    print(\"\\nUploading data now:\\n\")\n",
    "    \n",
    "    if token != \"\":\n",
    "        response_upload = w.upload(instances_fnames, token, space_name = \"dataset\")  \n",
    "\n",
    "        # Add specimen to dataset version\n",
    "        answer = input(\"Would you like to add the instances you created to a dataset version? yes (y) or no (n) \" ) \n",
    "        dsv_uuid = input(\"What is the uuid of the dataset version you would like to add specimen to? \")\n",
    "        token = getpass(prompt=\"Please enter your KG token (or Enter to skip uploading to the KG): \")\n",
    "        \n",
    "        print(\"\\nAdding specimen to dataset version:\" + dsv_uuid + \"\\n\")\n",
    "\n",
    "        # Retrieve the specimen information of the created instances\n",
    "        if 'SG_data' in locals():\n",
    "            SG2add = SG_data.specimen_uuid.unique().tolist()\n",
    "        else:\n",
    "            SG2add = []\n",
    "        if 'subject_data' in locals():\n",
    "            subjects2add = subject_data.specimen_uuid.unique().tolist()\n",
    "        else:\n",
    "            subjects2add = []\n",
    "        if 'tsc_data' in locals():\n",
    "            tsc2add = tsc_data.specimen_uuid.unique().tolist()\n",
    "        else:\n",
    "            tsc2add = []\n",
    "        if 'ts_data' in locals():\n",
    "            ts2add = ts_data.specimen_uuid.unique().tolist()\n",
    "        else:\n",
    "            ts2add = []\n",
    "        \n",
    "        instances2add = SG2add + subjects2add + tsc2add + ts2add\n",
    "\n",
    "        response_addition = w.add2dsv(instances2add, token, dsv_uuid, space_name = \"dataset\")\n",
    "\n",
    "    else: \n",
    "        print(\"No token provided\")  \n",
    "        \n",
    "elif answer == \"n\":\n",
    "    print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
